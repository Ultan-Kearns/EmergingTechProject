{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerging Technology Project notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Ultan Kearns - Student Number G00343745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The aim of this project is to train a model in Python using Keras to detect a digit drawn on the canvas in a Flask application and to utilize the model to specify which digit has been drawn by the user.  In the introduction section of this project I will outline my research methodology and explain the code I used to start to this application.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    I started out by importing the keras libraries needed for this module as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above lines import keras.models and keras.layers both are needed for this project.  According to the keras documentation listed here: https://keras.io/getting-started/sequential-model-guide/ the sequential model is a linear stack of layers, we can add layers to the sequential model using the dense library to set how many layers we wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import MNIST from keras.dataset\n",
    "from keras.datasets import mnist\n",
    "from keras import losses\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above lines of code import pacakages that are needed to train the AI.  Numpy is needed to generate random test data, keras.datasets imports the MNIST database of images which we need to train the AI, the imports losses and optimizers are needed to train the AI to detect the right images.  Both https://keras.io/datasets/ and https://keras.io/getting-started/sequential-model-guide/ gave me insight into the above code and how to use it to get my image classifier up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
